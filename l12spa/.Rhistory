Bryk$meanses <- mses[as.character(Bryk$school)]
Bryk[sample20, ]
str(mses)
mses[as.character(MathAchSchool$School[1:10])]  # for first 10 schools
mses
Bryk$meanses <- mses[as.character(Bryk$school)]
Bryk$cses <- Bryk$ses - Bryk$meanses  # school-centered SES
sector <- MathAchSchool$Sector
sector
names(sector) <- row.names(MathAchSchool)
Bryk$sector <- sector[as.character(Bryk$school)]
Bryk[sample20, ]
school <- Bryk$school
cat <- sample(unique(school[sector=='Catholic']), 18)
Cat.18 <- groupedData(mathach ~ ses | school,
data=Bryk[is.element(school, cat),])
pub <- sample(unique(school[sector=='Public']), 18)
?is.element
Pub.18 <- groupedData(mathach ~ ses | school,
data=Bryk[is.element(school, pub),])
library(lattice)
print(xyplot(mathach ~ ses | school, data=Cat.18, main="Catholic",
xlab="Centered SES", ylab="Math Achievement", layout=c(6, 3),
panel=function(x, y){
panel.xyplot(x, y)
panel.loess(x, y, span=1)
panel.lmline(x, y, lty=2)
}),
position=c(0, 0, 0.5, 1), more=TRUE)
print(xyplot(mathach ~ ses | school, data=Pub.18, main="Public",
xlab="Centered SES", ylab="Math Achievement",layout=c(6, 3),
panel=function(x, y){
panel.xyplot(x, y)
panel.loess(x, y, span=1)
panel.lmline(x, y, lty=2)
}),
position=c(0.5, 0, 1, 1))
cat.list <- lmList(mathach ~ ses | school, subset = sector=='Catholic',
data=Bryk)
pub.list <- lmList(mathach ~ ses | school, subset = sector=='Public',
data=Bryk)
print(plot(intervals(cat.list), main='Catholic'),
position=c(0, 0, 0.5, 1), more=TRUE)
str(cat.list)
cat.coef <- coef(cat.list)
cat.coef[1:10, ]
pub.coef <- coef(pub.list)
pub.coef[1:10, ]
par(mfrow=c(1,2))
boxplot(cat.coef[,1], pub.coef[,1], main='Intercepts',
names=c('Catholic', 'Public'))
boxplot(cat.coef[,2], pub.coef[,2], main='Slopes',
names=c('Catholic', 'Public'))
print(plot(intervals(cat.list), main='Catholic'),
position=c(0, 0, 0.5, 1), more=TRUE)
cat.list <- nlme:lmList(mathach ~ ses | school, subset = sector=='Catholic',
data=Bryk)
cat.list <- nlme::lmList(mathach ~ ses | school, subset = sector=='Catholic',
data=Bryk)
pub.list <- nlme::lmList(mathach ~ ses | school, subset = sector=='Public',
data=Bryk)
print(plot(intervals(cat.list), main='Catholic'),
position=c(0, 0, 0.5, 1), more=TRUE)
print(plot(intervals(pub.list), main='Public'),
position=c(0.5, 0, 1, 1))
library(RCurl)
library(XML)
i<-1
urli = paste("http://sh.lianjia.com/ershoufang/d", i, "s7", sep = "")
webi = getURL(urli, .encoding = "utf-8")
webi
cat(webi,file="temp.html")
getwd()
htmi = htmlParse(webi, encoding = "utf-8")
str(htmi)
str(webi)
nodi = getNodeSet(htmi, path = '//*[@id="house-lst"]/li[1]/div[2]/h2/a')
nodi
nodi = getNodeSet(htmi, path = "//div[@class='info-panel']//a[@name='selectDetail']")
nodi
nodi = getNodeSet(htmi, path = "//div[@class='info-panel']")
nodi = getNodeSet(htmi, path = "//div[@class='info-panel']")
nodi
str(nodi)
getNodeSet(htmi, path = "//div[@class='info-panel']")[1]
getNodeSet(htmi, path = "//div[@class='info-panel']/h2")[1]
getNodeSet(htmi, path = "//div[@class='info-panel']/h2/a")[1]
xmlValue(getNodeSet(htmi, path = "//div[@class='info-panel']/h2/a")[1])
sapply(getNodeSet(htmi, path = "//div[@class='info-panel']/h2/a")[1], xmlValue)
nodi<-getNodeSet(htmi, path = "//div[@class='info-panel']/h2/a")[1]
nodi<-getNodeSet(htmi, path = "//div[@class='info-panel']/h2/a")[1]
str(nodi)
nodi = getNodeSet(htmi, path = "//div[@class='info-panel']")
str(nodi)
nodi<-getNodeSet(htmi, path = "//div[@class='info-panel']/h2/a")[[1]]
xmlValue(nodi)
nodi<-getNodeSet(htmi, path = "//div[@class='info-panel']/h2/a")[1]
xmlValue(nodi[1])
xmlValue(nodi[[1]])
getNodeSet(htmi, path = "//div[@class='info-panel']/h2/a")[1]
getNodeSet(htmi, path = "//div[@class='info-panel']/h2/a")
xmlValue(nodi[[1]])
sapply(nodi[[1]], xmlValue)
sapply(nodi[1][[1]], xmlValue)
sapply(nodi[1], xmlValue)
sapply(nodi, xmlValue)
nodi = getNodeSet(htmi, path = "//div[@class='info-panel']")
sapply(nodi, xmlValue)
nodi = getNodeSet(htmi, path = "//div[@class='info-panel']/h2/a")
sapply(nodi, xmlValue)
nodi = getNodeSet(htmi, path = '//*[@id="house-lst"]/li[1]/div[2]/h2/a')
str(nodi)
xmlGetAttr(nodi,"title")
xmlGetAttr(nodi[[1]],"title")
biaoti = sapply(nodi, function(X) xmlGetAttr(X, "title"))
biaoti
Encoding(biaoti) = "UTF-8"
Encoding(biaoti) = "UTF-8"
biaoti
nodi = getNodeSet(htmi, path = "//div[@class='list-wrap']//div[@class='where']//span")
nodi
xhmi = sapply(nodi, xmlValue)
xhmi
nodi = getNodeSet(htmi, path = "//div[@class='list-wrap']//div[@class='where']/a/span")
nodi
xhmi = sapply(nodi, xmlValue)
xhmi
getNodeSet(htmi, path = "//div[@class='list-wrap']//div[@class='where']/span")
getNodeSet(htmi, path = "//div[@class='list-wrap']//div[@class='where']/span[1]")
getNodeSet(htmi, path = "//div[@class='list-wrap']//div[@class='where']/span[2]")
rm(list=ls())
library(httr)
url<-"http://bj.xiaozhu.com/fangzi/5098280314.html"
html<-GET(url)
headers(html)
str(html)
cookies(html)
doc<-content(html,"raw")
doc
doc<-content(html,"text")
doc
doc<-content(html,"raw")
doc<-content(html,"text")
doc<-content(html,"parsed")
xml_find_all(doc,"//h4")
html<-GET(url)
doc<-content(html,"text")
doc<-content(html,"parsed")
doc<-content(html,"parsed")
xml_find_all(doc,"//h4")
doc["h4"]
doc[h4]
doc[1]
doc[2]
xml_find_all(doc,"//h4")[1]
xml_find_all(doc,"/h4")
xml_find_all(doc,"//h4")
xml_find_all(doc,"//h4/em")
xml_text(xml_find_all(doc,"//h4/em"))
xml_find_all(doc,"//title")
xml_name(xml_find_all(doc,"//title"))
xml_text(xml_find_all(doc,"//title"))
xml_find_all(doc,"//head")
library(selectr)
querySelectorAll(doc, c("h6","h4"))
querySelectorAll(doc, c("//h6","//h4"))
querySelectorAll(doc, c("h6","h4"))
xml_find_all(doc, c("//h6","//h4"))
querySelectorAll(doc, c("h6","h4"))
getNodeSet(doc, c("//h6","//h4"))
library(XML)
getNodeSet(doc, c("//h6","//h4"))
url <-"http://bj.xiaozhu.com/fangzi/5098280314.html"
doc <- htmlTreeParse(url, useInternalNodes=T,encoding='utf-8')
getNodeSet(doc, c("//h6","//h4"))
getNodeSet(doc, "//h6")
biaoti<-xmlValue(getNodeSet(doc, "//h6"))
biaoti<-xmlValue(getNodeSet(doc, "//h6")[1])
biaoti
biaoti<-xmlValue(getNodeSet(doc, "//h6")[[1]])
doc<-htmlParse(html, encoding = "utf-8")
nodi = getNodeSet(doc, path ="//h6")
sapply(nodi, xmlValue)
url<-"http://bj.xiaozhu.com/fangzi/5112134313.html"
html<-getURL(url)
doc<-htmlParse(html)
nodi=getNodeSet(doc,'//*[@id="introducePart"]/div[5]/div[2]/div[1]/ul/li')
sapply(nodi, xmlValue)
sapply(nodi, xmlGetAttr)
sapply(nodi, function(x) xmlGetAttr(x))
nodi[1]
sapply(nodi, function(x) xmlGetAttr(x,"class"))
a<-sapply(nodi, xmlValue)
b<-sapply(nodi, function(x) xmlGetAttr(x,"class"))
cbind(a,b)
c-cbind(a,b)
c<-cbind(a,b)
View(c)
c[c$b!="s_ico_no"]
c<-as.data.frame(cbind(a,b))
View(c)
c[c$b!="s_ico_no"]
c[c$b!="s_ico_no",]
c[c$b!="s_ico_no",1]
names(a)<-b
a
a<-sapply(nodi, xmlValue)
a
b<-sapply(nodi, function(x) xmlGetAttr(x,"class"))
b
names(a)<-b
names(a)
a[s_ico_no]
d<-c(1,2,3)
d[1]
names(d)<-c("a","b","c")
d
d["a"]
a["s_ico_no"]
a[-"s_ico_no"]
?c
doc <- read_html(url)
xml_find_all(doc,"//h4")
xml_find_all(doc,"//h4/em")
xml_text(xml_find_all(doc,"//h4/em"))
xml_find_all(doc,"//title")
xml_name(xml_find_all(doc,"//title"))
xml_text(xml_find_all(doc,"//title"))
xml_find_all(doc,"//head")
xml_find(doc, "//h6")
xml_find_all(doc, "//h6")
xml_find_all(doc, "//h6")[1]
xml_find_all(doc,"//h4")[1]
xml_find_all(doc, c("//h6","//h4"))
xml_find_all(doc, "//a[@class='lorder_name']")[[1]]
library(selectr)
querySelectorAll(doc, c("h6","h4"))
querySelector(doc,"h4")
querySelectorAll(doc, c("h6","h4"),ns)
querySelectorAll(doc, c("h6","h4"),"class")
querySelectorAll(doc, c("h6","h4"))
html<-GET(url)
doc<-content(html,"parsed")
xml_find_all(doc,"//head")
querySelectorAll(doc, c("h6","h4"))
querySelector(doc,"h4")
html<-getURL(url)
doc<-htmlParse(html, encoding = "utf-8")
nodi = getNodeSet(doc, path ="//h6")
sapply(nodi, xmlValue)
querySelectorAll(doc, c("h6","h4"))
nodi = getNodeSet(doc, path =c("//h6","//h4"))
sapply(nodi, xmlValue)
library(selectr)
querySelectorAll(doc, c("h6","h4"))
querySelector(doc,"h4")
querySelectorNS(doc,"h4")
querySelectorAll(doc, c("h6,h4"))
doc <- read_html(url)
doc %>% html_nodes("h4") %>% html_text()
html_nodes(html,c("h4","h6")
# 使用CSS selector
#https://sjp.co.nz/projects/selectr/
library(selectr)
querySelectorAll(doc, "div.con_l > div.pho_info > h4")
xpath <- css_to_xpath("div.con_l > div.pho_info > h4")
xpath
#Here’s a small example working with an inline XML document:
#https://blog.rstudio.org/2015/04/21/xml2/
library(xml2)
x <- read_xml("<foo>
<bar>text <baz id = 'a' /></bar>
<bar>2</bar>
<baz id = 'b' />
</foo>")
xml_name(x)
#> [1] "foo"
xml_children(x)
#> {xml_nodeset (3)}
#> [1] <bar>text <baz id="a"/></bar>
#> [2] <bar>2</bar>
#> [3] <baz id="b"/>
# Find all baz nodes anywhere in the document
baz <- xml_find_all(x, ".//baz")
baz
#> {xml_nodeset (2)}
#> [1] <baz id="a"/>
#> [2] <baz id="b"/>
xml_path(baz)
#> [1] "/foo/bar[1]/baz" "/foo/baz"
xml_attr(baz, "id")
html_nodes(html,c("h4","h6"))
html_nodes(doc,c("h4","h6"))
nodi = getNodeSet(doc, path =c("//h6 | //h4"))
doc<-htmlParse(html, encoding = "utf-8")
nodi = getNodeSet(doc, path =c("//h6 | //h4"))
nodi = getNodeSet(doc, path =c("//h6 , //h4"))
html<-getURL(url)
str(html)
doc <- read_html(url)
doc %>% html_nodes("h4") %>% html_text()
html_nodes(doc,c("h4","h6"))
xml_node(doc,"h4")
library(RCurl)
html<-getURL(url)
doc <- read_html(html)
doc <- read_html(url)
xml_find_all(doc,"//h4")
xml_find_first(doc,"//h4")
xml_find_all(doc, c("//h6 | //h4"))
xml_find_all(doc, "//a[@class='lorder_name']")[[1]]
xml_find_all(doc, c("//h6 , //h4"))
xml_find_all(doc, "//h6 | //h4")
xml_find_all(doc,"//h4")
nodi = getNodeSet(doc, path ="//h6")
xmlValue(res.tree$doc$children$doc)
str(nodi)
xmlValue(nodi$doc)
nodi = getNodeSet(doc, path ="//h6")
doc<-htmlParse(html, encoding = "utf-8")
nodi = getNodeSet(doc, path ="//h6")
nodi = getNodeSet(doc, path =c("//h6","//h4"))
nodi = getNodeSet(doc, path =c("//h6 | //h4"))
sapply(nodi, xmlValue)
doc<-htmlTreeParse(html, encoding = "utf-8")
doc$children
xmlValue(doc$children[1])
xmlValue(doc$children[[1]])
xmlValue(doc$children$doc)
doc<-htmlParse(html, encoding = "utf-8")
nodi = getNodeSet(doc, path =c("//h6 | //h4"))
sapply(nodi, xmlValue)
sapply(nodi, xmlAttrs)
sapply(nodi, xmlParent)
sapply(nodi, xmlToList)
sapply(nodi, xmlSize)
xmlName
sapply(nodi, xmlName)
sapply(nodi, xmlGetAttr)
sapply(nodi, xmlGetAttr("h"))
sapply(nodi, xmlGetAttr("h3"))
doc<-htmlParse(html, encoding = "utf-8")
library(selectr)
querySelector(doc,"h4")
querySelectorAll(doc, c("h6","h4"))
querySelectorAll(doc, c("h6,h4"))
doc<-read_html(html, encoding = "utf-8")
querySelector(doc,"h4")
querySelectorAll(doc, c("h6","h4"))
querySelectorAll(doc, c("h6"|"h4"))
querySelectorAll(doc, c("h6 | h4"))
querySelector(doc,"h4")
querySelector(html,"h4")
str(doc)
querySelector(doc,"h4,h6")
querySelectorALL(doc,"h4,h6")
querySelectorAll(doc,"h4,h6")
doc<-read_html(html, encoding = "utf-8")
querySelector(doc,"h4")
querySelectorAll(doc,"h4,h6")
querySelectorAll(doc, c("h6","h4"))
doc<-read_html(html, encoding = "utf-8")
library(selectr)
querySelector(doc,"h4")
querySelectorAll(doc,"h4,h6")
doc<-htmlParse(html, encoding = "utf-8")
querySelectorNS(doc,"h4")
querySelectorAll(doc, c("h6","h4"))
querySelectorAll(doc, c("h6,h4"))
doc<-read_html(html, encoding = "utf-8")
querySelector(doc,"h4")
querySelectorAll(doc,"h4,h6")
doc<-htmlParse(html, encoding = "utf-8")
querySelectorAll(doc, c("h6","h4"))
library(rvest)
doc <- read_html(url)
doc %>% html_nodes("h4") %>% html_text()
doc %>% html_nodes("h4") %>% html_text()[1]
doc %>% html_nodes("h4") %>% html_text()[[1]]
doc %>% html_nodes("h4") %>% html_text()[1]
doc %>% html_nodes("h4") %>% html_text([1])
html_nodes(doc,c("h4","h6"))
html_nodes(doc,"h4,h6")
xml_node(doc,"h4")
xml_node(doc,"h4,h6")
xml_nodes(doc,"h4,h6")
xml_node(doc,"h4,h6")
html_node(doc,"h4,h6")
xml_nodes(doc,"h4,h6")
html_nodes(doc,"h4,h6")
url <-"http://bj.xiaozhu.com/fangzi/5098280314.html"
doc <- htmlTreeParse(url, useInternalNodes=T,encoding='utf-8')
nodi<-getNodeSet(doc, "//h4")
getNodeSet(doc, "//h4/em")
xml_find_all(doc,"//h4")
xml_nodes(doc,"//h4")
html_nodes(doc,"//h4")
querySelectorAll(doc, "//h4")
querySelectorAll(doc, "h4")
str(doc)
getNodeSet(doc, "//a[@class='lorder_name']")[[1]]
biaoti<-xmlValue(getNodeSet(doc, "//h6")[[1]])
Encoding(biaoti) = "UTF-8"
biaoti
querySelectorAll(doc, "h4")
querySelectorAll(doc, "h4,h6")
getNodeSet(doc, "//h4/em") %>%xmlValue()
getNodeSet(doc, "//h4/em")
sapply(getNodeSet(doc, "//h4/em") ,xmlValue)
xpathApply(doc,"//h4/em")
xpathSApply(doc,"//h4/em")
sapply(getNodeSet(doc, "//h4/em") ,xmlValue)
getNodeSet(doc,"title")
getNodeSet(doc,"//title")
getNodeSets(doc,"//title")
xmlNode(doc,"//title")
xmlNode(doc,"title")
xmlName(getNodeSet(doc,"//title"))
xmlName(getNodeSet(doc,"//title"))
sapply(getNodeSet(doc, "title") ,xmlValue)
sapply(getNodeSet(doc, "title") ,xmlName)
sapply(getNodeSet(doc, "//title") ,xmlName)
sapply(getNodeSet(doc, "//title") ,xmlValue)
xmlNode(html,"title")
xmlValue(xmlNode(html,"title"))
str(doc)
doc$head
xpathApply(doc,"//h4/em/text()")
getNodeSet(doc, "//h4/em/text()")
xpathApply(doc,"//h4/em")
getNodeSet(doc, "//h6/text()")
getNodeSet(doc, "//h6")
xpathApply(doc,"//h4/em/text()")
xpathApply(doc,"//h4/em")
sapply(getNodeSet(doc, "//h4/em") ,xmlValue)
getNodeSet(doc, "//h6/text()=1")
getNodeSet(doc, "//h6/text()<2")
getNodeSet(doc, "//h6/text()[position<2]")
getNodeSet(doc, "//h6/text()")
getNodeSet(doc, "//h6/text()[position()<2]")
doc[//title]
doc["//title"]
doc
doc["//title"]
doc <- htmlParse(url, useInternalNodes=T,encoding='utf-8')
nodi<-getNodeSet(doc, "//h4")
getNodeSet(doc, "//h4/em")
xpathApply(doc,"//h4/em")
xpathApply(doc,"//h4/em/text()")
sapply(getNodeSet(doc, "//h4/em") ,xmlValue)
getNodeSet(doc,"//title")
sapply(getNodeSet(doc, "//title") ,xmlName)
sapply(getNodeSet(doc, "//title") ,xmlValue)
doc["//title"]
doc <- htmlTreeParse(url,encoding='utf-8')
str(doc)
str(doc)
nodi<-getNodeSet(doc, "//h4")
getNodeSet(doc, "//h4/em")
doc$children$html$body["title"]
doc$children$html$body["//title"]
doc$children$html$head
doc$children$html$head
doc$children$html["head"]
doc <- htmlTreeParse(url, useInternalNodes=T,encoding='utf-8')
doc["//head"]
getNodeSet(doc,"//head")
xmlValue(xmlNode(html,"title"))
xmlValue(xmlNode(html,"//title"))
summary(getNodeSet(doc, "//h6"))
getNodeSet(doc, "//h6")
getNodeSet(doc, "//h6/text()")
getNodeSet(doc, "//h6/text()")
lenght(getNodeSet(doc, "//h6/text()"))
length(getNodeSet(doc, "//h6/text()"))
summary(getNodeSet(doc, "//h6"))
summary(getNodeSet(doc, "//h6/text()"))
length(getNodeSet(doc, "//h6/text()"))
sapply(getNodeSet(doc, "//h6") ,xmlValue)
sapply(getNodeSet(doc, "//h6") ,xmlValue)
getNodeSet(doc, "//h6/text()")
sapply(getNodeSet(doc, "//h6*") ,xmlValue)
getNodeSet(doc, "//h6//text()")
doc["//h6"]
doc["//h6/text()"]
getNodeSet(doc, "//h6/text(),//h4/text()")
getNodeSet(doc, "//h6/text() | //h4/text()")
getNodeSet(doc, "//a[@="lorder_name]")
xmlValue(xmlNode(html,"title"))
getNodeSet(doc, c("//h6","//h4"))
getNodeSet(doc, "//a[@class='lorder_name']")[[1]]
biaoti<-xmlValue(getNodeSet(doc, "//h6")[[1]])
Encoding(biaoti) = "UTF-8"
biaoti
library(selectr)
querySelectorAll(doc, "h4,h6")
url<-"http://bj.xiaozhu.com/fangzi/5112134313.html"
html<-getURL(url)
doc<-htmlParse(html)
nodi=getNodeSet(doc,'//*[@id="introducePart"]/div[5]/div[2]/div[1]/ul/li')
a<-sapply(nodi, xmlValue)
b<-sapply(nodi, function(x) xmlGetAttr(x,"class"))
names(a)<-b
a["s_ico_no"]
c<-as.data.frame(cbind(a,b))
c[c$b!="s_ico_no",1]
getNodeSet(doc, '//a[@="lorder_name"]')
getNodeSet(doc, '//a[@class="lorder_name"]')
getNodeSet(doc, '//*[@class="bg_box"]')
getNodeSet(doc, containtext("5分"))
??contain
getNodeSet(doc, text("5分"))
